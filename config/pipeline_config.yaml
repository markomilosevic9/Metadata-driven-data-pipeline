# pipeline config
# application-level settings that should remain consistent
# references environment variables using ${VAR_NAME} syntax

# spark
spark:
  master_url: "spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}"
  app_name: "MotorPolicyPipeline"
  
  # JARs required for minio/s3a connectivity
  jars:
    - "/opt/spark/jars/hadoop-aws-3.3.4.jar"
    - "/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar"
  
  # additional config for spark
  conf:
    spark.sql.adaptive.enabled: true
    spark.sql.adaptive.coalescePartitions.enabled: true

# minio config
storage:
  endpoint: "http://${MINIO_ENDPOINT}"
  access_key: "${MINIO_ROOT_USER}"
  secret_key: "${MINIO_ROOT_PASSWORD}"
  secure: ${MINIO_SECURE}
  path_style_access: true
  
  # minio buckets, logically follows structure of pipeline
  buckets:
    input: "input-data"
    output_ok: "motor-policy-ok"
    output_ko: "motor-policy-ko"
    output_ok_consolidated: "motor-policy-ok-consolidated"
    spark_logs: "spark-logs"
    pipeline_logs: "pipeline-logs"
    pipeline_state: "pipeline-state"

# pipeline config
pipeline:
  metadata_path: "config/metadata_motor.json"
  processing_mode: "incremental"
  
  # manifest configuration, used for tracking processed batches
  manifest:
    bucket: "pipeline-state"
    object_name: "motor-policy-manifest.json"
  
  # batch discovery settings
  batch_discovery:
    input_bucket: "input-data"
    batch_prefix: "batch-"
    date_format: "%Y-%m-%d"
  
  # data generation
  data_generation:
    total_records: 100000
    input_bucket: "input-data"
    seed: 42 # seed for reproducible dataset
    
    # batch configuration
    num_batches: 3
    batch_dates:
      - "2025-12-01"
      - "2025-12-02"
      - "2025-12-03"
    batch3_reuse_percentage: 0.2  # 20% of batch 3 records are valid records from batch 1

# testing config
testing:
  spark_master: "spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}"
  markers:
    pre_pipeline: "not post_pipeline"
    post_pipeline: "post_pipeline"

# logging config
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# environment
environment: "${ENVIRONMENT}"